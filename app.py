# -*- coding: utf-8 -*-
"""
Urdu Quranic Chatbot Web Application
Flask backend for the Quranic Q&A system with improved accuracy
and integration with a pre-created search model
"""

from flask import Flask, render_template, request, jsonify
import json
import random
import time
import re
import os
from difflib import SequenceMatcher
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import string
import logging
from pathlib import Path

# Import the model wrapper
from local_model_loader import QuranModelWrapper

app = Flask(__name__)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger('QuranChatbot')

# Path to the JSON data file
DATA_FILE = os.path.join(os.path.dirname(__file__), 'qa_data.json')

# Initialize the model wrapper
model_path = Path("./models/processed_quran.pkl")
model_wrapper = QuranModelWrapper(model_path)

# Global cache for QA data
qa_data_cache = None

# Category mappings for reuse
CATEGORY_TITLES = {
    "structure": "Ù‚Ø±Ø¢Ù† Ú©Ø§ ØªØ¹Ø§Ø±Ù",
    "revelation": "Ù‚Ø±Ø¢Ù† Ú©Ø§ Ù†Ø²ÙˆÙ„",
    "prophets": "Ø§Ù†Ø¨ÛŒØ§Ø¡ Ú©Ø±Ø§Ù…",
    "special_verses": "Ø®Ø§Øµ Ø¢ÛŒØ§Øª",
    "mentions": "Ù…Ø®ØªÙ„Ù Ø°Ú©Ø±",
    "islamic_history": "Ø§Ø³Ù„Ø§Ù…ÛŒ ØªØ§Ø±ÛŒØ®"
}

CATEGORY_ICONS = {
    "structure": "fa-book-open",
    "revelation": "fa-moon",
    "prophets": "fa-user",
    "special_verses": "fa-star",
    "mentions": "fa-list",
    "islamic_history": "fa-history"
}

CATEGORY_KEYWORDS = {
    "structure": ["Ù¾Ø§Ø±Û", "Ø³ÙˆØ±Øª", "Ø¢ÛŒØª", "Ø±Ú©ÙˆØ¹", "Ø­Ø±ÙˆÙ", "Ø§Ù„ÙØ§Ø¸"],
    "revelation": ["Ù†Ø²ÙˆÙ„", "ÙˆØ­ÛŒ", "Ù†Ø§Ø²Ù„", "Ù…Ú©Û", "Ù…Ø¯ÛŒÙ†Û"],
    "prophets": ["Ù†Ø¨ÛŒ", "Ù¾ÛŒØºÙ…Ø¨Ø±", "Ø±Ø³ÙˆÙ„", "Ù…Ø­Ù…Ø¯", "Ø¹ÛŒØ³ÛŒÙ°", "Ù…ÙˆØ³ÛŒÙ°"],
    "special_verses": ["Ø®Ø§Øµ", "ÙØ¶ÛŒÙ„Øª", "Ù…Ø´ÛÙˆØ±", "Ø¨Ú‘ÛŒ", "Ú†Ú¾ÙˆÙ¹ÛŒ"],
    "mentions": ["Ø°Ú©Ø±", "Ú©ØªÙ†ÛŒ Ø¨Ø§Ø±", "Ù†Ø§Ù…", "Ú©ØªÙ†ÛŒ Ø¯ÙØ¹Û"],
    "islamic_history": ["Ù¾ÛÙ„Ø§", "Ø³Ø¨ Ø³Û’ Ù¾ÛÙ„Û’", "Ø§Ø³Ù„Ø§Ù… Ú©Ø§ Ø¢ØºØ§Ø²", "Ø´ÛÛŒØ¯", "Ø®Ø§ØªÙˆÙ†"]
}

# Dictionary of prophet-related patterns and their answers
PROPHET_QUESTIONS = {
    "most_mentioned_prophet": {
        "patterns": [
            "Ø³Ø¨ Ø³Û’ Ø²ÛŒØ§Ø¯Û Ø°Ú©Ø± Ú©Ø³ Ù†Ø¨ÛŒ Ú©Ø§",
            "Ú©Ø³ Ù†Ø¨ÛŒ Ú©Ø§ Ø³Ø¨ Ø³Û’ Ø²ÛŒØ§Ø¯Û Ø°Ú©Ø±",
            "Ú©Ø³ Ù¾ÛŒØºÙ…Ø¨Ø± Ú©Ø§ Ø³Ø¨ Ø³Û’ Ø²ÛŒØ§Ø¯Û Ø°Ú©Ø±",
            "Ø³Ø¨ Ø³Û’ Ø²ÛŒØ§Ø¯Û Ú©Ø³ Ù†Ø¨ÛŒ Ú©Ø§ Ø°Ú©Ø±",
            "Ú©ÙˆÙ†Ø³Û’ Ù†Ø¨ÛŒ Ú©Ø§ Ø³Ø¨ Ø³Û’ Ø²ÛŒØ§Ø¯Û Ø°Ú©Ø±"
        ],
        "answer": """Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ø³Ø¨ Ø³Û’ Ø²ÛŒØ§Ø¯Û Ø­Ø¶Ø±Øª Ù…ÙˆØ³ÛŒÙ° Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… Ú©Ø§ Ø°Ú©Ø± Ø¢ÛŒØ§ ÛÛ’Û” Ø§Ù† Ú©Ø§ Ù†Ø§Ù… ÛŒØ§ Ø§Ù† Ø³Û’ Ù…ØªØ¹Ù„Ù‚ ÙˆØ§Ù‚Ø¹Ø§Øª ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ 136 Ù…Ø±ØªØ¨Û Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ø¨ÛŒØ§Ù† ÛÙˆØ¦Û’ ÛÛŒÚºÛ” Ø¯ÙˆØ³Ø±Û’ Ù†Ù…Ø¨Ø± Ù¾Ø± Ø­Ø¶Ø±Øª Ø§Ø¨Ø±Ø§ÛÛŒÙ… Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… (69 Ù…Ø±ØªØ¨Û) Ø§ÙˆØ± Ù¾Ú¾Ø± Ø­Ø¶Ø±Øª Ù†ÙˆØ­ Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… (43 Ù…Ø±ØªØ¨Û) Ú©Ø§ Ø°Ú©Ø± ÛÛ’Û” Ø­Ø¶Ø±Øª Ù…Ø­Ù…Ø¯ ï·º Ú©Ø§ Ù†Ø§Ù… Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº ØµØ±Ù 4 Ù…Ø±ØªØ¨Û Ø¢ÛŒØ§ ÛÛ’ Ù„ÛŒÚ©Ù† Ø¢Ù¾ Ú©Ùˆ Ù…Ø®ØªÙ„Ù Ø§Ù„Ù‚Ø§Ø¨ Ø³Û’ Ø¨ÛØª Ø²ÛŒØ§Ø¯Û Ø®Ø·Ø§Ø¨ Ú©ÛŒØ§ Ú¯ÛŒØ§ ÛÛ’Û”"""
    },
    "prophet_jesus_mentions": {
        "patterns": [
            "Ú©ØªÙ†ÛŒ Ø¨Ø§Ø± Ø­Ø¶Ø±Øª Ø¹ÛŒØ³ÛŒÙ°",
            "Ø¹ÛŒØ³ÛŒÙ° Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… Ú©Ø§ Ø°Ú©Ø±",
            "Ø­Ø¶Ø±Øª Ø¹ÛŒØ³ÛŒÙ° Ú©Ø§ Ú©ØªÙ†Ø§ Ø°Ú©Ø±",
            "Ø¹ÛŒØ³ÛŒÙ° Ú©Ø§ Ù†Ø§Ù… Ú©ØªÙ†ÛŒ Ø¨Ø§Ø±"
        ],
        "answer": """Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ø­Ø¶Ø±Øª Ø¹ÛŒØ³ÛŒÙ° Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… Ú©Ø§ Ø°Ú©Ø± 25 Ù…Ø±ØªØ¨Û Ø¢ÛŒØ§ ÛÛ’Û” Ø§Ù† Ú©Ø§ Ù†Ø§Ù… 'Ø¹ÛŒØ³ÛŒÙ°' Ú©Û’ Ø·ÙˆØ± Ù¾Ø± 25 Ø¨Ø§Ø± Ø¢ÛŒØ§ ÛÛ’ØŒ Ø§ÙˆØ± 'Ø§Ø¨Ù† Ù…Ø±ÛŒÙ…' (Ù…Ø±ÛŒÙ… Ú©Û’ Ø¨ÛŒÙ¹Û’) Ú©Û’ Ø·ÙˆØ± Ù¾Ø± Ø¨Ú¾ÛŒ Ú©Ø¦ÛŒ Ø¨Ø§Ø± Ø°Ú©Ø± Ú©ÛŒØ§ Ú¯ÛŒØ§ ÛÛ’Û” Ø­Ø¶Ø±Øª Ø¹ÛŒØ³ÛŒÙ° Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… Ú©Ø§ Ø°Ú©Ø± 11 Ù…Ø®ØªÙ„Ù Ø³ÙˆØ±ØªÙˆÚº Ù…ÛŒÚº Ø¢ÛŒØ§ ÛÛ’ØŒ Ø¨Ø´Ù…ÙˆÙ„ Ø³ÙˆØ±Ûƒ Ø§Ù„Ø¨Ù‚Ø±ÛØŒ Ø¢Ù„ Ø¹Ù…Ø±Ø§Ù†ØŒ Ø§Ù„Ù†Ø³Ø§Ø¡ØŒ Ø§Ù„Ù…Ø§Ø¦Ø¯ÛØŒ Ø§Ù„Ø£Ù†Ø¹Ø§Ù…ØŒ Ù…Ø±ÛŒÙ…ØŒ Ø§Ù„Ø£Ø­Ø²Ø§Ø¨ØŒ Ø§Ù„Ø´ÙˆØ±ÛŒÙ°ØŒ Ø§Ù„Ø²Ø®Ø±ÙØŒ Ø§Ù„Ø­Ø¯ÛŒØ¯ Ø§ÙˆØ± Ø§Ù„ØµÙÛ”"""
    },
    "prophet_ibrahim_mentions": {
        "patterns": [
            "Ú©ØªÙ†ÛŒ Ø¨Ø§Ø± Ø­Ø¶Ø±Øª Ø§Ø¨Ø±Ø§ÛÛŒÙ…",
            "Ø§Ø¨Ø±Ø§ÛÛŒÙ… Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… Ú©Ø§ Ø°Ú©Ø±",
            "Ø­Ø¶Ø±Øª Ø§Ø¨Ø±Ø§ÛÛŒÙ… Ú©Ø§ Ú©ØªÙ†Ø§ Ø°Ú©Ø±",
            "Ø§Ø¨Ø±Ø§ÛÛŒÙ… Ú©Ø§ Ù†Ø§Ù… Ú©ØªÙ†ÛŒ Ø¨Ø§Ø±"
        ],
        "answer": """Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ø­Ø¶Ø±Øª Ø§Ø¨Ø±Ø§ÛÛŒÙ… Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… Ú©Ø§ Ø°Ú©Ø± 69 Ù…Ø±ØªØ¨Û Ø¢ÛŒØ§ ÛÛ’Û” Ø§Ù† Ú©Ø§ ØªØ°Ú©Ø±Û 25 Ø³ÙˆØ±ØªÙˆÚº Ù…ÛŒÚº Ù…Ù„ØªØ§ ÛÛ’ØŒ Ø¬Ø³ Ù…ÛŒÚº Ø³ÙˆØ±Ûƒ Ø§Ù„Ø¨Ù‚Ø±ÛØŒ Ø¢Ù„ Ø¹Ù…Ø±Ø§Ù†ØŒ Ø§Ù„Ù†Ø³Ø§Ø¡ØŒ Ø§Ù„Ø§Ù†Ø¹Ø§Ù…ØŒ ÛÙˆØ¯ØŒ Ø§Ø¨Ø±Ø§ÛÛŒÙ…ØŒ Ø§Ù„Ø­Ø¬Ø±ØŒ Ù…Ø±ÛŒÙ…ØŒ Ø§Ù„Ø§Ù†Ø¨ÛŒØ§Ø¡ØŒ Ø§Ù„Ø­Ø¬ØŒ Ø§Ù„Ø´Ø¹Ø±Ø§Ø¡ØŒ Ø§Ù„Ø¹Ù†Ú©Ø¨ÙˆØªØŒ Ø§Ù„ØµØ§ÙØ§ØªØŒ ØµØŒ Ø§Ù„Ø´ÙˆØ±ÛŒÙ°ØŒ Ø§Ù„Ø²Ø®Ø±ÙØŒ Ø§Ù„Ø°Ø§Ø±ÛŒØ§ØªØŒ Ø§Ù„Ù†Ø¬Ù…ØŒ Ø§Ù„Ø­Ø¯ÛŒØ¯ØŒ Ø§Ù„Ù…Ù…ØªØ­Ù†ÛØŒ Ø§ÙˆØ± Ø§Ù„Ø§Ø¹Ù„ÛŒ Ø´Ø§Ù…Ù„ ÛÛŒÚºÛ”"""
    },
    "prophet_muhammad_mentions": {
        "patterns": [
            "Ú©ØªÙ†ÛŒ Ø¨Ø§Ø± Ø­Ø¶Ø±Øª Ù…Ø­Ù…Ø¯",
            "Ù…Ø­Ù…Ø¯ ØµÙ„ÛŒ Ø§Ù„Ù„Û Ø¹Ù„ÛŒÛ ÙˆØ³Ù„Ù… Ú©Ø§ Ø°Ú©Ø±",
            "Ø­Ø¶Ø±Øª Ù…Ø­Ù…Ø¯ Ú©Ø§ Ú©ØªÙ†Ø§ Ø°Ú©Ø±",
            "Ù…Ø­Ù…Ø¯ Ú©Ø§ Ù†Ø§Ù… Ú©ØªÙ†ÛŒ Ø¨Ø§Ø±"
        ],
        "answer": """Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ø­Ø¶Ø±Øª Ù…Ø­Ù…Ø¯ ï·º Ú©Ø§ Ù†Ø§Ù… Ø¨Ø±Ø§Û Ø±Ø§Ø³Øª ØµØ±Ù 4 Ù…Ø±ØªØ¨Û Ø¢ÛŒØ§ ÛÛ’Û” ÛŒÛ Ø°Ú©Ø± Ø³ÙˆØ±Ûƒ Ø¢Ù„ Ø¹Ù…Ø±Ø§Ù† (Ø¢ÛŒØª 144)ØŒ Ø³ÙˆØ±Ûƒ Ø§Ù„Ø£Ø­Ø²Ø§Ø¨ (Ø¢ÛŒØª 40)ØŒ Ø³ÙˆØ±Ûƒ Ù…Ø­Ù…Ø¯ (Ø¢ÛŒØª 2) Ø§ÙˆØ± Ø³ÙˆØ±Ûƒ Ø§Ù„ÙØªØ­ (Ø¢ÛŒØª 29) Ù…ÛŒÚº Ù…Ù„ØªØ§ ÛÛ’Û” ØªØ§ÛÙ…ØŒ Ø¢Ù¾ Ú©Ø§ Ø°Ú©Ø± Ù…Ø®ØªÙ„Ù Ø§Ù„Ù‚Ø§Ø¨ Ø¬ÛŒØ³Û’ 'Ø±Ø³ÙˆÙ„'ØŒ 'Ù†Ø¨ÛŒ'ØŒ 'Ø¨Ø´ÛŒØ±'ØŒ 'Ù†Ø°ÛŒØ±'ØŒ Ø§ÙˆØ± 'Ù…Ø²Ù…Ù„' ÙˆØºÛŒØ±Û Ú©Û’ Ø³Ø§ØªÚ¾ Ø¨ÛØª Ø²ÛŒØ§Ø¯Û Ø¨Ø§Ø± Ø¢ÛŒØ§ ÛÛ’Û” Ø§Ú¯Ø± Ø§Ù† ØªÙ…Ø§Ù… Ø§Ø´Ø§Ø±ÙˆÚº Ú©Ùˆ Ø´Ù…Ø§Ø± Ú©ÛŒØ§ Ø¬Ø§Ø¦Û’ ØªÙˆ ÛŒÛ ØªØ¹Ø¯Ø§Ø¯ 70 Ø³Û’ Ø²ÛŒØ§Ø¯Û ÛÛ’Û”"""
    },
    "prophet_noah_mentions": {
        "patterns": [
            "Ú©ØªÙ†ÛŒ Ø¨Ø§Ø± Ø­Ø¶Ø±Øª Ù†ÙˆØ­",
            "Ù†ÙˆØ­ Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… Ú©Ø§ Ø°Ú©Ø±",
            "Ø­Ø¶Ø±Øª Ù†ÙˆØ­ Ú©Ø§ Ú©ØªÙ†Ø§ Ø°Ú©Ø±",
            "Ù†ÙˆØ­ Ú©Ø§ Ù†Ø§Ù… Ú©ØªÙ†ÛŒ Ø¨Ø§Ø±"
        ],
        "answer": """Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ø­Ø¶Ø±Øª Ù†ÙˆØ­ Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… Ú©Ø§ Ø°Ú©Ø± ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ 43 Ù…Ø±ØªØ¨Û Ø¢ÛŒØ§ ÛÛ’Û” Ø­Ø¶Ø±Øª Ù†ÙˆØ­ Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº ØªÛŒØ³Ø±Û’ Ø³Ø¨ Ø³Û’ Ø²ÛŒØ§Ø¯Û Ø°Ú©Ø± Ú©ÛŒÛ’ Ø¬Ø§Ù†Û’ ÙˆØ§Ù„Û’ Ù†Ø¨ÛŒ ÛÛŒÚºØŒ Ø­Ø¶Ø±Øª Ù…ÙˆØ³ÛŒÙ° Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… (136 Ø¨Ø§Ø±) Ø§ÙˆØ± Ø­Ø¶Ø±Øª Ø§Ø¨Ø±Ø§ÛÛŒÙ… Ø¹Ù„ÛŒÛ Ø§Ù„Ø³Ù„Ø§Ù… (69 Ø¨Ø§Ø±) Ú©Û’ Ø¨Ø¹Ø¯Û” Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ø§ÛŒÚ© Ù¾ÙˆØ±ÛŒ Ø³ÙˆØ±Øª 'Ø³ÙˆØ±Ûƒ Ù†ÙˆØ­' Ø¨Ú¾ÛŒ Ù†Ø§Ø²Ù„ ÛÙˆØ¦ÛŒ ÛÛ’ Ø¬Ùˆ Ú©Û Ù‚Ø±Ø¢Ù† Ú©ÛŒ 71ÙˆÛŒÚº Ø³ÙˆØ±Øª ÛÛ’Û”"""
    },
    "total_prophets_quran": {
        "patterns": [
            "Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ú©ØªÙ†Û’ Ø§Ù†Ø¨ÛŒØ§Ø¡",
            "Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ú©ØªÙ†Û’ Ù†Ø¨ÛŒÙˆÚº",
            "Ú©ØªÙ†Û’ Ù¾ÛŒØºÙ…Ø¨Ø±ÙˆÚº Ú©Û’ Ù†Ø§Ù…",
            "Ú©ØªÙ†Û’ Ø§Ù†Ø¨ÛŒØ§Ø¡ Ú©Ø§ ØªØ°Ú©Ø±Û"
        ],
        "answer": """Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ú©Ù„ 25 Ø§Ù†Ø¨ÛŒØ§Ø¡ Ú©Ø±Ø§Ù… Ú©Ø§ Ù†Ø§Ù… Ù„Û’ Ú©Ø± Ø°Ú©Ø± Ú©ÛŒØ§ Ú¯ÛŒØ§ ÛÛ’Û” ÛŒÛ Ø§Ù†Ø¨ÛŒØ§Ø¡ Ú©Ø±Ø§Ù… ÛÛŒÚº: Ø¢Ø¯Ù…ØŒ Ø§Ø¯Ø±ÛŒØ³ØŒ Ù†ÙˆØ­ØŒ ÛÙˆØ¯ØŒ ØµØ§Ù„Ø­ØŒ Ø§Ø¨Ø±Ø§ÛÛŒÙ…ØŒ Ù„ÙˆØ·ØŒ Ø§Ø³Ù…Ø§Ø¹ÛŒÙ„ØŒ Ø§Ø³Ø­Ø§Ù‚ØŒ ÛŒØ¹Ù‚ÙˆØ¨ØŒ ÛŒÙˆØ³ÙØŒ Ø§ÛŒÙˆØ¨ØŒ Ø´Ø¹ÛŒØ¨ØŒ Ù…ÙˆØ³ÛŒØŒ ÛØ§Ø±ÙˆÙ†ØŒ Ø°ÙˆØ§Ù„Ú©ÙÙ„ØŒ Ø¯Ø§Ø¤Ø¯ØŒ Ø³Ù„ÛŒÙ…Ø§Ù†ØŒ Ø§Ù„ÛŒØ§Ø³ØŒ Ø§Ù„ÛŒØ³Ø¹ØŒ ÛŒÙˆÙ†Ø³ØŒ Ø²Ú©Ø±ÛŒØ§ØŒ ÛŒØ­ÛŒÛŒÙ°ØŒ Ø¹ÛŒØ³ÛŒÙ° Ø§ÙˆØ± Ù…Ø­Ù…Ø¯ (Ø¹Ù„ÛŒÛÙ… Ø§Ù„Ø³Ù„Ø§Ù…)Û” Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ø§Ù† Ú©Û’ Ø¹Ù„Ø§ÙˆÛ Ø¨Ú¾ÛŒ Ú©Ú†Ú¾ Ø§Ù†Ø¨ÛŒØ§Ø¡ Ú©Ø§ Ø°Ú©Ø± ÛÛ’ØŒ Ù„ÛŒÚ©Ù† Ø§Ù† Ú©Û’ Ù†Ø§Ù… Ù†ÛÛŒÚº Ø¨ØªØ§Ø¦Û’ Ú¯Ø¦Û’ ÛÛŒÚºÛ”"""
    }
}

# Intent detection patterns
GREETING_PATTERNS = [
    "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…", "Ø³Ù„Ø§Ù…", "Ø¢Ø¯Ø§Ø¨", "ÛÛŒÙ„Ùˆ", "ÛØ§Ø¦Û’", "Ø§Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…", "Ø¬ÛŒ ", 
    "hello", "hi ", "hey", "assalam", "salam"
]

THANKS_WORDS = ["Ø´Ú©Ø±ÛŒÛ", "Ù…ÛØ±Ø¨Ø§Ù†ÛŒ", "Ø§Ø­Ø³Ø§Ù†", "Ù…Ù…Ù†ÙˆÙ†", "ØªÚ¾ÛŒÙ†Ú©Ø³", "thanks", "thank you", "thanks a lot"]
FAREWELL_WORDS = ["Ø§Ù„Ù„Û Ø­Ø§ÙØ¸", "Ø®Ø¯Ø§ Ø­Ø§ÙØ¸", "ÙÛŒ Ø§Ù…Ø§Ù† Ø§Ù„Ù„Û", "Ø§Ù„ÙˆØ¯Ø§Ø¹", "Ø¨Ø§Ø¦Û’", "bye", "goodbye", "see you"]
HELP_WORDS = ["Ù…Ø¯Ø¯", "help", "Ú©ÛŒØ³Û’", "how to", "guide", "explain"]
HISTORY_KEYWORDS = ["Ù¾ÛÙ„Ø§", "Ø³Ø¨ Ø³Û’ Ù¾ÛÙ„Û’", "Ø§Ø³Ù„Ø§Ù… Ú©Ø§ Ø¢ØºØ§Ø²", "Ø´ÛÛŒØ¯", "Ø®Ø§ØªÙˆÙ†"]

# Try to pre-load the model at startup
if model_path.exists():
    model_wrapper.load()
    logger.info(f"Pre-loaded model from {model_path}")
else:
    logger.warning(f"Model not found at {model_path}. Will try to create fallback database.")

def load_qa_data(force_reload=False):
    """Load the question-answer data from JSON file with optional caching"""
    global qa_data_cache
    
    # Return cached data if available and not forcing reload
    if qa_data_cache is not None and not force_reload:
        return qa_data_cache
    
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as file:
            qa_data_cache = json.load(file)
            logger.info(f"Loaded QA data from {DATA_FILE}")
            return qa_data_cache
    except Exception as e:
        logger.error(f"Error loading QA data: {e}")
        # Return minimal data structure in case of error
        return {"questions": [], "categories": {}, "facts": [], 
                "greetings": [], "thank_you_responses": [], 
                "farewell_responses": [], "not_found_responses": []}

def get_question_by_id(question_id, data):
    """Get question by ID with O(1) complexity using dictionary lookup"""
    # Create a lookup dictionary if it doesn't exist
    if not hasattr(get_question_by_id, "lookup_dict"):
        get_question_by_id.lookup_dict = {}
        
    # Rebuild lookup if data has changed
    if id(data) not in get_question_by_id.lookup_dict:
        lookup = {}
        for question in data.get("questions", []):
            if "id" in question:
                lookup[question["id"]] = question
        get_question_by_id.lookup_dict[id(data)] = lookup
    
    # Return the question or None
    return get_question_by_id.lookup_dict[id(data)].get(question_id)

def preprocess_text(text, is_urdu=True):
    """Clean and normalize text for better matching"""
    if not text:
        return ""
        
    # For Urdu text
    if is_urdu:
        # Remove Urdu punctuation
        text = re.sub(r'[Û”ØŒØŸ!Ø›:\(\)]', ' ', text)
    else:
        # For English parts
        # Remove punctuation
        text = text.translate(str.maketrans('', '', string.punctuation))
        # Convert to lowercase
        text = text.lower()
        
    # Normalize whitespace for both
    return re.sub(r'\s+', ' ', text).strip()

def tokenize_urdu(text):
    """Tokenize Urdu text into words"""
    # Basic tokenization by whitespace
    tokens = text.split()
    # Further clean tokens
    return [token.strip() for token in tokens if token.strip()]

def advanced_similarity_score(query, reference, is_urdu=True):
    """Calculate advanced similarity between query and reference texts"""
    # Preprocess both texts
    query_processed = preprocess_text(query, is_urdu)
    reference_processed = preprocess_text(reference, is_urdu)
    
    # Method 1: String Sequence Matching
    sequence_similarity = SequenceMatcher(None, query_processed, reference_processed).ratio()
    
    # Method 2: Word Overlap
    if is_urdu:
        query_tokens = tokenize_urdu(query_processed)
        reference_tokens = tokenize_urdu(reference_processed)
    else:
        # For English, use more advanced NLP
        query_tokens = word_tokenize(query_processed)
        reference_tokens = word_tokenize(reference_processed)
        
        # Remove stopwords for English
        stop_words = set(stopwords.words('english'))
        query_tokens = [w for w in query_tokens if w not in stop_words]
        reference_tokens = [w for w in reference_tokens if w not in stop_words]
        
        # Stem words for English
        stemmer = PorterStemmer()
        query_tokens = [stemmer.stem(w) for w in query_tokens]
        reference_tokens = [stemmer.stem(w) for w in reference_tokens]
    
    # Count matching words
    matching_words = sum(1 for word in query_tokens if word in reference_tokens)
    
    # Calculate word overlap ratio
    total_words = len(set(query_tokens + reference_tokens))
    word_overlap = matching_words / total_words if total_words > 0 else 0
    
    # Combined similarity (weighted average)
    return (0.6 * sequence_similarity) + (0.4 * word_overlap)

def find_matching_question(user_input, qa_data):
    """Find the best matching question using advanced methods"""
    processed_input = preprocess_text(user_input)
    
    # Direct match check with higher threshold for short queries
    for question in qa_data.get("questions", []):
        question_text = question.get("question", "")
        if advanced_similarity_score(processed_input, question_text) > 0.8:
            return question
        
        # Check alternative phrasings
        for alt in question.get("alternative_phrasings", []):
            if advanced_similarity_score(processed_input, alt) > 0.8:
                return question
    
    # Keyword matching with improved weighting
    best_match = None
    highest_score = 0
    
    # Lower threshold for short queries
    threshold = 2 if len(processed_input.split()) <= 3 else 3
    
    for question in qa_data.get("questions", []):
        score = 0
        
        # Check for keywords
        for keyword in question.get("keywords", []):
            if keyword.lower() in processed_input.lower():
                # Weight longer keywords more (improved algorithm)
                score += (len(keyword) ** 1.5) * 0.1
        
        # Add category weighting
        if "category" in question and question["category"] in CATEGORY_KEYWORDS:
            for cat_keyword in CATEGORY_KEYWORDS[question["category"]]:
                if cat_keyword in processed_input.lower():
                    score += 2  # Boost category relevance
        
        if score > highest_score:
            highest_score = score
            best_match = question
    
    # Return keyword match if score is above threshold
    if highest_score >= threshold:
        return best_match
    
    # Fuzzy matching as a fallback
    best_match = None
    highest_similarity = 0
    
    for question in qa_data.get("questions", []):
        similarity = advanced_similarity_score(processed_input, question.get("question", ""))
        if similarity > highest_similarity:
            highest_similarity = similarity
            best_match = question
    
    if highest_similarity > 0.5:
        return best_match
    
    return None

def get_related_questions(question, qa_data):
    """Get related questions with smart fallback"""
    related = []
    
    if not question or "related_questions" not in question:
        # Determine category from user input if possible
        matched_category = None
        
        if question and isinstance(question, dict) and "category" in question:
            matched_category = question["category"]
        elif isinstance(question, str):
            for cat, keywords in CATEGORY_KEYWORDS.items():
                if any(kw in question for kw in keywords):
                    matched_category = cat
                    break
        
        # Get questions from the matched category or popular questions
        if matched_category:
            cat_questions = [q for q in qa_data.get("questions", []) if q.get("category") == matched_category]
            related = cat_questions[:3]
        else:
            # Popular questions as fallback
            popular_ids = ["quran_paras", "quran_surahs", "longest_surah", "shortest_surah"]
            for qid in popular_ids:
                q = get_question_by_id(qid, qa_data)
                if q:
                    related.append(q)
    else:
        # Get explicitly related questions
        for q_id in question.get("related_questions", []):
            q = get_question_by_id(q_id, qa_data)
            if q:
                related.append(q)
    
    return related[:3]  # Limit to 3 related questions

def detect_intent(text):
    """Detect the intent of the user's message"""
    if not text:
        return "question"  # Default
        
    text_lower = text.lower()
    
    # Historical intent detection
    if any(word in text_lower for word in HISTORY_KEYWORDS):
        return "history"
    
    # Greeting detection
    if any(greeting in text_lower for greeting in GREETING_PATTERNS):
        return "greeting"
    
    # Thanks
    if any(word in text_lower for word in THANKS_WORDS):
        return "thanks"
    
    # Farewell
    if any(farewell in text_lower for farewell in FAREWELL_WORDS):
        return "farewell"
    
    # Help
    if any(word in text_lower for word in HELP_WORDS):
        return "help"
    
    # Default to question
    return "question"

def detect_specific_questions(user_input):
    """Detect specific high-priority questions that need direct answers"""
    if not user_input:
        return None
        
    # Normalize user input for matching
    normalized_input = preprocess_text(user_input).lower()
    
    # Check each question pattern
    for q_type, data in PROPHET_QUESTIONS.items():
        for pattern in data["patterns"]:
            if pattern in normalized_input:
                return {
                    "type": q_type,
                    "answer": data["answer"]
                }
    
    return None

def search_quran(query):
    """Search Quran using the loaded model and include all relevant matches"""
    if not query or not model_wrapper.loaded:
        return None
        
    try:
        # Get search results
        results = model_wrapper.search(query)
        
        if "error" in results:
            logger.warning(f"Search error: {results['error']}")
            return None
            
        if results["primary_match"]:
            primary = results["primary_match"]
            # Format the answer with the verse and reference (improved spacing)
            answer = f"{primary['verse']}\n\nğŸ“– {primary['reference']}"
            
            # Include all matches in the answer if available
            other_matches = results.get("other_matches", [])
            if other_matches:
                answer += "\n\n**Ù…Ø²ÛŒØ¯ Ù…ØªØ¹Ù„Ù‚Û Ù†ØªØ§Ø¦Ø¬:**\n"
                for i, match in enumerate(other_matches, 1):
                    other_match_text = f"{i}. {match['verse']}\nğŸ“– {match['reference']}"
                    answer += other_match_text + "\n\n"
            
            # Create related suggestions from other matches
            suggestions = []
            related_queries = []
            
            for match in other_matches:
                # Extract a potential follow-up question from the verse
                verse_parts = match['verse'].split('ØŒ')
                if len(verse_parts) > 1:
                    q = verse_parts[0] + "ØŸ"
                    if len(q) > 10 and len(q) < 60:  # Reasonable question length
                        related_queries.append(q)
                        
            # If we have related queries, add them to suggestions
            if related_queries:
                suggestions.extend(related_queries[:2])
            
            # Add some general follow-up questions
            suggestions.append(f"Ù…Ø²ÛŒØ¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª {query} Ú©Û’ Ø¨Ø§Ø±Û’ Ù…ÛŒÚº")
            
            return {
                "answer": answer,
                "suggestions": suggestions
            }
        
        return None
        
    except Exception as e:
        logger.error(f"Error in search_quran: {e}")
        return None

def process_question(user_input, qa_data):
    """Process user input and return appropriate response"""
    if not user_input:
        return {
            'answer': "Ú©ÙˆØ¦ÛŒ Ø³ÙˆØ§Ù„ Ù†ÛÛŒÚº Ù…Ù„Ø§Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”",
            'confidence': 'none',
            'intent': 'unknown'
        }
    
    # First check for specific high-priority questions
    specific_question = detect_specific_questions(user_input)
    if specific_question:
        related = []
        if specific_question["type"].startswith("prophet_") or specific_question["type"] == "most_mentioned_prophet":
            # Get related questions for prophets
            for q in qa_data.get("questions", []):
                if q.get("category") == "prophets" and q.get("id", "") != specific_question["type"]:
                    related.append(q)
                    if len(related) >= 3:
                        break
        
        return {
            'answer': specific_question["answer"],
            'confidence': 'high',
            'suggestions': [q["question"] for q in related] if related else ["Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ú©ØªÙ†ÛŒ Ø¨Ø§Ø± Ø­Ø¶Ø±Øª Ø§Ø¨Ø±Ø§ÛÛŒÙ… Ú©Ø§ Ø°Ú©Ø± Ø¢ÛŒØ§ ÛÛ’"],
            'intent': 'question',
            'source': 'specific_answers'
        }
    
    # Detect intent
    intent = detect_intent(user_input)
    
    if intent == "greeting":
        return {
            'answer': random.choice(qa_data.get("greetings", ["ÙˆØ¹Ù„ÛŒÚ©Ù… Ø§Ù„Ø³Ù„Ø§Ù…!"])),
            'suggestions': [q["question"] for q in get_related_questions(None, qa_data)],
            'confidence': 'high',
            'intent': 'greeting'
        }
    
    if intent == "thanks":
        return {
            'answer': random.choice(qa_data.get("thank_you_responses", ["Ø¢Ù¾ Ú©Ø§ Ø´Ú©Ø±ÛŒÛ!"])),
            'suggestions': ["Ù…Ø²ÛŒØ¯ Ø³ÙˆØ§Ù„Ø§Øª", "Ø§Ù„Ù„Û Ø­Ø§ÙØ¸"],
            'confidence': 'high',
            'intent': 'thanks'
        }
    
    if intent == "farewell":
        return {
            'answer': random.choice(qa_data.get("farewell_responses", ["Ø§Ù„Ù„Û Ø­Ø§ÙØ¸!"])),
            'farewell': True,
            'confidence': 'high',
            'intent': 'farewell'
        }
    
    if intent == "help":
        help_text = """Ø¢Ù¾ Ù‚Ø±Ø¢Ù† Ú©Û’ Ø¨Ø§Ø±Û’ Ù…ÛŒÚº Ú©ÙˆØ¦ÛŒ Ø¨Ú¾ÛŒ Ø³ÙˆØ§Ù„ Ù¾ÙˆÚ†Ú¾ Ø³Ú©ØªÛ’ ÛÛŒÚºØŒ Ø¬ÛŒØ³Û’:
- Ù‚Ø±Ø¢Ù† Ú©ØªÙ†Û’ Ù¾Ø§Ø±ÙˆÚº Ù¾Ø± Ù…Ø´ØªÙ…Ù„ ÛÛ’ØŸ
- Ø³Ø¨ Ø³Û’ Ø·ÙˆÛŒÙ„ Ø³ÙˆØ±Ûƒ Ú©ÙˆÙ† Ø³ÛŒ ÛÛ’ØŸ
- Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ú©ØªÙ†ÛŒ Ø³ÙˆØ±ØªÛŒÚº ÛÛŒÚºØŸ
- Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº Ú©Ø³ Ù¾ÛŒØºÙ…Ø¨Ø± Ú©Ø§ Ø³Ø¨ Ø³Û’ Ø²ÛŒØ§Ø¯Û Ø°Ú©Ø± ÛÛ’ØŸ"""
        return {
            'answer': help_text,
            'suggestions': [q["question"] for q in get_related_questions(None, qa_data)[:4]],
            'confidence': 'high',
            'intent': 'help'
        }
    
    # Process as a question
    match = find_matching_question(user_input, qa_data)
    
    if match:
        # Direct match from QA database
        related = get_related_questions(match, qa_data)
        return {
            'answer': match["answer"],
            'confidence': 'high',
            'suggestions': [q["question"] for q in related],
            'intent': 'question',
            'source': 'qa_database'
        }
    else:
        # Try using the search model if no match found
        search_result = None
        if model_wrapper.loaded:
            search_result = search_quran(user_input)
        
        if search_result:
            # Match from search model
            return {
                'answer': search_result["answer"],
                'confidence': 'medium',
                'suggestions': search_result["suggestions"],
                'intent': 'question',
                'source': 'search_model'
            }
        else:
            # No match found
            not_found = random.choice(qa_data.get("not_found_responses", 
                              ["Ù…Ø¹Ø§Ù Ú©ÛŒØ¬ÛŒÛ’ØŒ Ù…ÛŒÚº Ø§Ø³ Ø³ÙˆØ§Ù„ Ú©Ø§ Ø¬ÙˆØ§Ø¨ Ù†ÛÛŒÚº Ø¬Ø§Ù†ØªØ§Û”"]))
            return {
                'answer': not_found,
                'confidence': 'none',
                'suggestions': [q["question"] for q in get_related_questions(None, qa_data)],
                'intent': 'unknown'
            }

# Routes
@app.route('/')
def home():
    """Render the home page"""
    # Ensure model is loaded
    if not model_wrapper.loaded and model_path.exists():
        model_wrapper.load()
    return render_template('index.html')

@app.route('/ask', methods=['POST'])
def ask():
    """Process the user's question and return an answer"""
    user_input = request.json.get('question', '')
    qa_data = load_qa_data()
    
    # Add slight delay to simulate thinking
    time.sleep(0.2)
    
    # Process the question using our improved engine
    result = process_question(user_input, qa_data)
    
    return jsonify(result)

@app.route('/check-model', methods=['GET'])
def check_model():
    """API endpoint to check if the model is loaded"""
    try:
        is_loaded = model_wrapper.loaded
        model_exists = model_path.exists()
        
        if is_loaded:
            status = "Model is loaded and ready"
            model_type = model_wrapper.model_type if hasattr(model_wrapper, 'model_type') else "unknown"
        elif model_exists:
            status = "Model file exists but is not loaded yet"
            model_type = "unknown"
        else:
            status = "Model file not found"
            model_type = "none"
            
        return jsonify({
            'success': is_loaded,
            'model_exists': model_exists,
            'model_type': model_type,
            'status': status,
            'model_path': str(model_path)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/popular-questions')
def popular_questions():
    """Return a list of popular questions for suggestions"""
    qa_data = load_qa_data()
    popular_ids = ["quran_paras", "quran_surahs", "longest_surah", "shortest_surah"]
    popular = []
    
    for q_id in popular_ids:
        q = get_question_by_id(q_id, qa_data)
        if q:
            popular.append(q["question"])
    
    return jsonify({'questions': popular})

@app.route('/daily-fact')
def daily_fact():
    """Return two random Quranic facts"""
    qa_data = load_qa_data()
    facts = random.sample(qa_data.get("facts", ["Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº 114 Ø³ÙˆØ±ØªÛŒÚº ÛÛŒÚºÛ”"]), 
                        min(2, len(qa_data.get("facts", ["Ù‚Ø±Ø¢Ù† Ù…ÛŒÚº 114 Ø³ÙˆØ±ØªÛŒÚº ÛÛŒÚºÛ”"]))))
    return jsonify({'facts': facts})

@app.route('/categories')
def get_categories():
    """Return categories and their questions"""
    qa_data = load_qa_data()
    result = {}
    
    # Group questions by category
    category_questions = {}
    for question in qa_data.get("questions", []):
        if "category" in question:
            category = question["category"]
            if category not in category_questions:
                category_questions[category] = []
            category_questions[category].append(question["question"])
    
    # Create result object
    for category, questions in category_questions.items():
        result[category] = {
            "title": CATEGORY_TITLES.get(category, category),
            "icon": CATEGORY_ICONS.get(category, "fa-question"),
            "questions": questions[:4]  # Limit to 4 questions per category
        }
    
    return jsonify(result)

@app.route('/search', methods=['POST'])
def search():
    """Search for questions matching a query"""
    query = request.json.get('query', '')
    qa_data = load_qa_data()
    
    if len(query) < 2:
        return jsonify({'results': []})
    
    results = []
    for q in qa_data.get("questions", []):
        # Check main question
        if query.lower() in q["question"].lower():
            results.append({
                'question': q["question"],
                'preview': q["answer"][:50] + "..." if len(q["answer"]) > 50 else q["answer"]
            })
            continue
        
        # Check alternative phrasings
        for alt in q.get("alternative_phrasings", []):
            if query.lower() in alt.lower():
                results.append({
                    'question': q["question"],
                    'preview': q["answer"][:50] + "..." if len(q["answer"]) > 50 else q["answer"]
                })
                break
    
    return jsonify({'results': results[:5]})  # Limit to 5 results

@app.route('/load-model', methods=['POST'])
def load_model():
    """API endpoint to explicitly load the model"""
    try:
        if model_wrapper.loaded:
            return jsonify({
                'success': True,
                'message': 'Model is already loaded',
                'model_type': model_wrapper.model_type if hasattr(model_wrapper, 'model_type') else "unknown"
            })
        
        if not model_path.exists():
            return jsonify({
                'success': False,
                'message': f'Model file not found at {model_path}'
            }), 404
            
        success = model_wrapper.load()
        
        if success:
            return jsonify({
                'success': True,
                'message': 'Model loaded successfully',
                'model_type': model_wrapper.model_type if hasattr(model_wrapper, 'model_type') else "unknown"
            })
        else:
            return jsonify({
                'success': False,
                'message': 'Failed to load model'
            }), 500
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/reload-qa-data', methods=['POST'])
def reload_qa_data():
    """API endpoint to reload the QA data"""
    try:
        # Store the current data for comparison
        old_data = None
        qa_file = Path(DATA_FILE)
        if qa_file.exists():
            try:
                with open(qa_file, "r", encoding="utf-8") as f:
                    old_data = json.load(f)
            except Exception as e:
                logger.error(f"Failed to load existing QA data: {e}")
        
        # Force reload from file
        global qa_data_cache
        qa_data_cache = None  # Clear cache
        new_data = load_qa_data(force_reload=True)
        
        # Check if data was successfully loaded
        if not new_data:
            return jsonify({
                'success': False,
                'message': 'Failed to load new QA data'
            }), 500
        
        # Compare data sizes to give feedback
        old_count = len(old_data.get("questions", [])) if old_data else 0
        new_count = len(new_data.get("questions", [])) if new_data else 0
        
        # Reset the lookup dictionary in get_question_by_id
        if hasattr(get_question_by_id, "lookup_dict"):
            get_question_by_id.lookup_dict = {}
        
        return jsonify({
            'success': True,
            'message': f'QA data reloaded successfully. {old_count} -> {new_count} questions',
            'old_count': old_count,
            'new_count': new_count
        })
    except Exception as e:
        logger.error(f"Error reloading QA data: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

if __name__ == '__main__':
    # Try to pre-load the model when starting the server
    if model_path.exists() and not model_wrapper.loaded:
        try:
            model_wrapper.load()
            logger.info(f"Pre-loaded model from {model_path}")
        except Exception as e:
            logger.error(f"Failed to pre-load model: {e}")
    
    app.run(debug=True)
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11243377,"sourceType":"datasetVersion","datasetId":7024897}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport re\n\n# Install required packages\n# !pip install transformers datasets sentencepiece\n\n# Global variables\nvectorizer = None\ntfidf_matrix = None\ntokenizer = None\nmodel = None\n\n# Load the raw text data directly - handle the case where these are actual Quranic verses\n# instead of a properly formatted CSV\ntry:\n    # First, check if the data has already been processed from a previous run\n    try:\n        urdu_data = pd.read_csv('/kaggle/working/processed_quran.csv')\n        print(\"Found previously processed data. Loading it...\")\n    except:\n        # Try loading from multiple possible kaggle paths\n        possible_paths = [\n            '/kaggle/input/urdu-quran-dataset/Urdu.csv',\n            '/kaggle/input/urdu-quran/Urdu.csv',\n            '/kaggle/input/urdu-csv/Urdu.csv',\n            '/kaggle/input/urdu-quran-translation/Urdu.csv',\n            '/kaggle/working/Urdu.csv'\n        ]\n        \n        for path in possible_paths:\n            try:\n                # Try reading the file as raw text first\n                with open(path, 'r', encoding='utf-8') as f:\n                    lines = f.readlines()\n                \n                print(f\"Successfully read {len(lines)} lines from {path}\")\n                \n                # Create a DataFrame with the verses\n                verses = []\n                for i, line in enumerate(lines):\n                    line = line.strip()\n                    if line:  # Skip empty lines\n                        verses.append({\n                            \"Surah\": i // 10 + 1,  # Assign artificial surah numbers\n                            \"Ayah\": i % 10 + 1,    # Assign artificial ayah numbers\n                            \"Translation\": line\n                        })\n                \n                urdu_data = pd.DataFrame(verses)\n                \n                # Save the processed data for future use\n                urdu_data.to_csv('/kaggle/working/processed_quran.csv', index=False)\n                \n                print(f\"Created DataFrame with {len(verses)} verses\")\n                break\n            except Exception as e:\n                print(f\"Error reading {path}: {str(e)}\")\n                continue\n        else:\n            # If we get here, none of the paths worked\n            # As a fallback, create a DataFrame from the error text itself\n            print(\"Using error messages as data source...\")\n            \n            # Extract verse text from error messages\n            pattern = r\"Error processing row: (.*?), Error:\"\n            with open('/kaggle/working/error_log.txt', 'r', encoding='utf-8') as f:\n                error_text = f.read()\n            \n            matches = re.findall(pattern, error_text)\n            \n            if matches:\n                verses = []\n                for i, verse in enumerate(matches):\n                    verses.append({\n                        \"Surah\": i // 10 + 1,  # Arbitrary surah assignment\n                        \"Ayah\": i % 10 + 1,    # Arbitrary ayah assignment\n                        \"Translation\": verse\n                    })\n                urdu_data = pd.DataFrame(verses)\n                print(f\"Created DataFrame with {len(verses)} verses from error log\")\n            else:\n                # Last resort - create a small dummy dataset\n                test_verses = [\n                    \"بسم اللہ الرحمن الرحیم\",\n                    \"الحمد للہ رب العالمین\",\n                    \"الرحمن الرحیم\",\n                    \"مالک یوم الدین\",\n                    \"ایاک نعبد و ایاک نستعین\",\n                    \"اھدنا الصراط المستقیم\",\n                    \"صراط الذین انعمت علیھم غیر المغضوب علیھم و لا الضالین\"\n                ]\n                verses = []\n                for i, verse in enumerate(test_verses):\n                    verses.append({\n                        \"Surah\": 1,\n                        \"Ayah\": i + 1,\n                        \"Translation\": verse\n                    })\n                urdu_data = pd.DataFrame(verses)\n                print(\"Created small sample dataset with Surah Al-Fatiha\")\nexcept Exception as e:\n    print(f\"Error during data loading: {str(e)}\")\n    # Create a minimal dataset as a fallback\n    urdu_data = pd.DataFrame([\n        {\"Surah\": 1, \"Ayah\": 1, \"Translation\": \"بسم اللہ الرحمن الرحیم\"},\n        {\"Surah\": 1, \"Ayah\": 2, \"Translation\": \"الحمد للہ رب العالمین\"},\n        {\"Surah\": 1, \"Ayah\": 3, \"Translation\": \"الرحمن الرحیم\"}\n    ])\n    print(\"Created minimal fallback dataset\")\n\n# Check if we have any data to work with\nif urdu_data.empty:\n    print(\"Error: No data available. Please check the input files.\")\n    exit()\n\n# Check if 'Translation' column exists\nif 'Translation' not in urdu_data.columns:\n    print(\"Error: 'Translation' column not found. Check data format.\")\n    exit()\n\n# Now we can proceed with the chatbot setup\nprint(\"\\nProcessed data sample:\")\nprint(urdu_data.head())\nprint(f\"Total verses: {len(urdu_data)}\")\n\n# Initialize NLP components\ntry:\n    global tokenizer, model, vectorizer, tfidf_matrix\n    \n    # Initialize tokenizer and model\n    print(\"\\nInitializing NLP components...\")\n    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n    model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-multilingual-cased\")\n    \n    # Create the TF-IDF vectorizer and fit it on the translations\n    print(\"Fitting TF-IDF vectorizer...\")\n    vectorizer = TfidfVectorizer(stop_words=None)  # Don't use English stopwords for Urdu\n    tfidf_matrix = vectorizer.fit_transform(urdu_data['Translation'])\n    print(\"TF-IDF vectorizer fitted successfully.\")\nexcept Exception as e:\n    print(f\"Error initializing NLP components: {str(e)}\")\n    print(\"Will attempt to continue with limited functionality.\")\n\ndef find_relevant_context(question, dataset, top_k=3):\n    \"\"\"\n    Find relevant Quranic verses for a given question.\n    Uses both exact matching and TF-IDF similarity if available.\n    \n    Args:\n        question: The question in Urdu\n        dataset: The processed Quran dataset\n        top_k: Number of verses to return\n        \n    Returns:\n        String containing relevant verses with references\n    \"\"\"\n    global vectorizer, tfidf_matrix\n    \n    # Step 1: Try an exact match or substring match for critical words\n    exact_matches = []\n    for _, row in dataset.iterrows():\n        # Check if question is contained in the verse or vice versa\n        if question in row['Translation'] or any(word in row['Translation'] for word in question.split()):\n            exact_matches.append(f\"Surah {row['Surah']}, Ayah {row['Ayah']}: {row['Translation']}\")\n            if len(exact_matches) >= top_k:\n                break\n\n    if exact_matches:\n        print(f\"Found {len(exact_matches)} matches for question: '{question}'\")\n        return \"\\n\".join(exact_matches)\n\n    # Step 2: If no exact matches and vectorizer is available, use TF-IDF\n    if vectorizer is not None and tfidf_matrix is not None:\n        try:\n            query_tfidf = vectorizer.transform([question])\n            cosine_similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n            \n            # Get the indices of the top_k most similar translations\n            most_similar_indices = cosine_similarities.argsort()[-top_k:][::-1]\n            \n            results = []\n            for idx in most_similar_indices:\n                row = dataset.iloc[idx]\n                similarity_score = cosine_similarities[idx]\n                # Only include results with some minimal similarity\n                if similarity_score > 0.01:  # Lower threshold for Urdu\n                    results.append(f\"Surah {row['Surah']}, Ayah {row['Ayah']}: {row['Translation']} (similarity: {similarity_score:.2f})\")\n            \n            if results:\n                print(f\"Found {len(results)} similar verses using TF-IDF\")\n                return \"\\n\".join(results)\n        except Exception as e:\n            print(f\"Error during TF-IDF similarity: {str(e)}\")\n    \n    # Step 3: Last resort - return a few random verses if no matches\n    import random\n    if len(dataset) > 0:\n        random_indices = random.sample(range(min(len(dataset), 20)), min(top_k, len(dataset)))\n        results = []\n        for idx in random_indices:\n            row = dataset.iloc[idx]\n            results.append(f\"Surah {row['Surah']}, Ayah {row['Ayah']}: {row['Translation']} (random selection)\")\n        \n        print(f\"No matches found. Returning {len(results)} random verses.\")\n        return \"\\n\".join(results)\n    \n    return \"معذرت، کوئی متعلقہ آیت نہیں مل سکی۔\"\n\ndef urdu_chatbot():\n    \"\"\"Interactive Urdu Quran chatbot function\"\"\"\n    global tokenizer, model\n    \n    print(\"Quranic Urdu Chatbot: قرآن سے متعلق سوال پوچھیں۔ (exit لکھ کر باہر نکلیں)\")\n    \n    # Check if we can create the QA pipeline\n    try:\n        qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n        pipeline_available = True\n    except Exception as e:\n        print(f\"Warning: Could not initialize QA pipeline: {str(e)}\")\n        print(\"Will proceed with basic context retrieval only.\")\n        pipeline_available = False\n\n    while True:\n        user_question = input(\"آپ: \")\n        if user_question.lower() == \"exit\":\n            print(\"چَیٹ بوٹ: اللہ حافظ!\")\n            break\n\n        # Find context\n        try:\n            context = find_relevant_context(user_question, urdu_data)\n            if not context:\n                print(\"چَیٹ بوٹ: معذرت، میں اس سوال کا جواب نہیں دے سکتا۔\")\n                continue\n            \n            # If we have a pipeline, use it for QA\n            if pipeline_available:\n                try:\n                    result = qa_pipeline(question=user_question, context=context, max_length=512)\n                    print(f\"چَیٹ بوٹ: {result['answer']}\")\n                except Exception as e:\n                    print(f\"چَیٹ بوٹ: {context}\\n\\n(معذرت، QA پائپ لائن میں مسئلہ: {str(e)})\")\n            else:\n                # Just return the context if no pipeline\n                print(f\"چَیٹ بوٹ: {context}\")\n        except Exception as e:\n            print(f\"چَیٹ بوٹ: معذرت، میں اس سوال کا جواب دینے سے قاصر ہوں۔ (Error: {str(e)})\")\n\n# Test the function with a sample question\nprint(\"\\n--- Testing Chatbot ---\")\ntest_question = \"رحمن\"\nprint(f\"Testing with question: '{test_question}'\")\n\ntry:\n    test_context = find_relevant_context(test_question, urdu_data)\n    print(f\"Context for '{test_question}':\")\n    print(test_context)\nexcept Exception as e:\n    print(f\"Error during testing: {str(e)}\")\n\n# Uncomment to run the interactive chatbot\n# urdu_chatbot()\n\nprint(\"\\nScript completed successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:04:43.476647Z","iopub.execute_input":"2025-04-01T18:04:43.476972Z","iopub.status.idle":"2025-04-01T18:04:55.067605Z","shell.execute_reply.started":"2025-04-01T18:04:43.476950Z","shell.execute_reply":"2025-04-01T18:04:55.066626Z"}},"outputs":[{"name":"stdout","text":"Error reading /kaggle/input/urdu-quran-dataset/Urdu.csv: [Errno 2] No such file or directory: '/kaggle/input/urdu-quran-dataset/Urdu.csv'\nError reading /kaggle/input/urdu-quran/Urdu.csv: [Errno 2] No such file or directory: '/kaggle/input/urdu-quran/Urdu.csv'\nSuccessfully read 6237 lines from /kaggle/input/urdu-csv/Urdu.csv\nCreated DataFrame with 6237 verses\n\nProcessed data sample:\n   Surah  Ayah                                        Translation\n0      1     1                            ﻿Surah,Ayah,Translation\n1      1     2  1,1,شروع الله کا نام لے کر جو بڑا مہربان نہایت...\n2      1     3  1,2,سب طرح کی تعریف خدا ہی کو (سزاوار) ہے جو ت...\n3      1     4                      1,3,بڑا مہربان نہایت رحم والا\n4      1     5                            1,4,انصاف کے دن کا حاکم\nTotal verses: 6237\n\nInitializing NLP components...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5fe20b81c584ee89857796a23c49b16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf2e931390fc4d9e942b2c7a96c5a4da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56fb44b3d9e24bd6af4e3671258634cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca874e7dcd144be0aede0a4cb5caf86a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2fc32d12a947d795b3ba6cf421ed16"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Fitting TF-IDF vectorizer...\nTF-IDF vectorizer fitted successfully.\n\n--- Testing Chatbot ---\nTesting with question: 'رحمن'\nNo matches found. Returning 3 random verses.\nContext for 'رحمن':\nSurah 1, Ayah 8: 1,7,ان لوگوں کے رستے جن پر تو اپنا فضل وکرم کرتا رہا نہ ان کے جن پر غصے ہوتا رہا اور نہ گمراہوں کے (random selection)\nSurah 1, Ayah 6: 1,5,(اے پروردگار) ہم تیری ہی عبادت کرتے ہیں اور تجھ ہی سے مدد مانگتے ہیں (random selection)\nSurah 2, Ayah 3: 2,5,یہی لوگ اپنے پروردگار (کی طرف) سے ہدایت پر ہیں اور یہی نجات پانے والے ہیں (random selection)\n\nScript completed successfully.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport re\nimport os\nimport json\nimport pickle\nfrom pathlib import Path\nimport difflib\nfrom collections import defaultdict\nimport logging\nimport warnings\nimport unicodedata\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[logging.StreamHandler()]\n)\nlogger = logging.getLogger('QuranSearchEngine')\n\n# Suppress specific warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\nclass EnhancedQuranSearchEngine:\n    \"\"\"\n    Enhanced Quran Search Engine with multi-technique search capabilities\n    and comprehensive reference handling.\n    \"\"\"\n    \n    def __init__(self, cache_dir=\"/kaggle/working/quran_cache\"):\n        \"\"\"Initialize the search engine with various search techniques\"\"\"\n        self.cache_dir = Path(cache_dir)\n        self.cache_dir.mkdir(exist_ok=True, parents=True)\n        \n        self.data = None\n        self.surah_names = {}\n        self.vectorizer = None\n        self.tfidf_matrix = None\n        self.sentence_transformer = None\n        self.sentence_embeddings = None\n        self.qa_model = None\n        self.qa_tokenizer = None\n        self.index_map = {}  # For mapping between different verse numbering systems\n        \n        logger.info(\"Initializing Enhanced Quran Search Engine\")\n        \n    def normalize_arabic_text(self, text):\n        \"\"\"Normalize Arabic/Urdu text by removing diacritics and standardizing characters\"\"\"\n        # Handle None or non-string inputs\n        if not isinstance(text, str):\n            return \"\"\n            \n        # Remove diacritics (harakat)\n        text = ''.join(c for c in unicodedata.normalize('NFKD', text) \n                      if not unicodedata.combining(c))\n        \n        # Standardize certain characters\n        text = text.replace('ی', 'ي')  # Standardize ya\n        text = text.replace('ۃ', 'ة')  # Standardize ta marbutah\n        text = text.replace('ك', 'ک')  # Standardize kaf\n        \n        return text\n    \n    def load_data_from_multiple_sources(self):\n        \"\"\"Load Quran data from multiple possible sources, with fallbacks\"\"\"\n        # 1. Try to load from cache first\n        cache_path = self.cache_dir / \"processed_quran.pkl\"\n        if cache_path.exists():\n            try:\n                logger.info(f\"Loading data from cache: {cache_path}\")\n                with open(cache_path, 'rb') as f:\n                    self.data = pickle.load(f)\n                return True\n            except Exception as e:\n                logger.warning(f\"Failed to load from cache: {e}\")\n        \n        # 2. Try multiple possible file locations\n        possible_paths = [\n            # Standard Kaggle paths\n            '/kaggle/input/urdu-quran-dataset/Urdu.csv',\n            '/kaggle/input/urdu-quran/Urdu.csv',\n            '/kaggle/input/urdu-csv/Urdu.csv',\n            '/kaggle/input/quran-urdu-translation/quran-urdu.csv',\n            '/kaggle/input/urdu-quran-translation/Urdu.csv',\n            '/kaggle/working/Urdu.csv',\n            # Common local paths\n            'data/quran-urdu.csv',\n            'quran-data/Urdu.csv',\n            # Plain text file possibilities\n            '/kaggle/input/urdu-quran-dataset/quran.txt',\n            '/kaggle/input/urdu-quran/quran.txt'\n        ]\n        \n        for path in possible_paths:\n            try:\n                # Try to determine the file type and read appropriately\n                if path.endswith('.csv'):\n                    logger.info(f\"Attempting to read CSV file: {path}\")\n                    # First try with standard CSV format\n                    try:\n                        df = pd.read_csv(path)\n                        if all(col in df.columns for col in ['Surah', 'Ayah', 'Translation']):\n                            self.data = df\n                            logger.info(f\"Successfully loaded standard CSV: {path}\")\n                            break\n                    except Exception as e:\n                        logger.debug(f\"Failed to read as standard CSV: {e}\")\n                    \n                    # Try with delimiters\n                    for delimiter in [',', '|', '\\t']:\n                        try:\n                            df = pd.read_csv(path, delimiter=delimiter, header=None)\n                            if df.shape[1] >= 3:\n                                # Assume first 3 columns are Surah, Ayah, Translation\n                                df.columns = ['Surah', 'Ayah', 'Translation'] + [f'Extra{i}' for i in range(df.shape[1]-3)]\n                                self.data = df\n                                logger.info(f\"Successfully loaded delimited file: {path} with delimiter: {delimiter}\")\n                                break\n                        except Exception as e:\n                            logger.debug(f\"Failed to read with delimiter {delimiter}: {e}\")\n                    \n                    # Try as plain text with no header\n                    if self.data is None:\n                        try:\n                            df = pd.read_csv(path, header=None, names=['Text'], encoding='utf-8')\n                            verses = []\n                            for i, row in df.iterrows():\n                                if not isinstance(row['Text'], str):\n                                    continue\n                                parts = row['Text'].split('|')\n                                if len(parts) >= 3:\n                                    try:\n                                        surah, ayah = int(parts[0]), int(parts[1])\n                                        translation = parts[2]\n                                        verses.append({\"Surah\": surah, \"Ayah\": ayah, \"Translation\": translation})\n                                    except (ValueError, TypeError):\n                                        continue\n                            \n                            if verses:\n                                self.data = pd.DataFrame(verses)\n                                logger.info(f\"Successfully parsed plain text CSV: {path}\")\n                                break\n                        except Exception as e:\n                            logger.debug(f\"Failed to read as plain text: {e}\")\n                \n                # Try as plain text file\n                elif path.endswith('.txt'):\n                    logger.info(f\"Attempting to read text file: {path}\")\n                    try:\n                        with open(path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                        \n                        verses = []\n                        for i, line in enumerate(lines):\n                            line = line.strip()\n                            if not line:\n                                continue\n                                \n                            # Check if line has a format like \"1:1 - Translation\"\n                            match = re.match(r'(\\d+):(\\d+)\\s*[-–]\\s*(.*)', line)\n                            if match:\n                                surah, ayah, translation = match.groups()\n                                verses.append({\n                                    \"Surah\": int(surah),\n                                    \"Ayah\": int(ayah),\n                                    \"Translation\": translation.strip()\n                                })\n                            else:\n                                # Assign artificial numbers\n                                verses.append({\n                                    \"Surah\": (i // 10) + 1, \n                                    \"Ayah\": (i % 10) + 1,\n                                    \"Translation\": line\n                                })\n                        \n                        if verses:\n                            self.data = pd.DataFrame(verses)\n                            logger.info(f\"Successfully parsed text file: {path}\")\n                            break\n                    except Exception as e:\n                        logger.warning(f\"Failed to read text file {path}: {e}\")\n            \n            except Exception as e:\n                logger.warning(f\"Error processing {path}: {e}\")\n                continue\n        \n        # 3. Try to extract from error messages if needed\n        if self.data is None:\n            logger.info(\"Attempting to extract data from error messages\")\n            try:\n                error_files = [\n                    '/kaggle/working/error_log.txt',\n                    'error_log.txt'\n                ]\n                \n                for error_file in error_files:\n                    if os.path.exists(error_file):\n                        with open(error_file, 'r', encoding='utf-8') as f:\n                            error_text = f.read()\n                        \n                        pattern = r\"Error processing row: (.*?), Error:\"\n                        matches = re.findall(pattern, error_text)\n                        \n                        if matches:\n                            verses = []\n                            for i, verse in enumerate(matches):\n                                verses.append({\n                                    \"Surah\": (i // 10) + 1,\n                                    \"Ayah\": (i % 10) + 1,\n                                    \"Translation\": verse.strip()\n                                })\n                            \n                            self.data = pd.DataFrame(verses)\n                            logger.info(f\"Created dataset from error log: {error_file}\")\n                            break\n            except Exception as e:\n                logger.warning(f\"Failed to extract from error log: {e}\")\n        \n        # 4. Create dataset from direct text input\n        if self.data is None and 'paste.txt' in possible_paths:\n            logger.info(\"Attempting to create dataset from paste.txt content\")\n            try:\n                with open('paste.txt', 'r', encoding='utf-8') as f:\n                    text = f.read()\n                \n                # Extract error messages containing verses\n                pattern = r\"Error processing row: (.*?), Error: invalid literal for int\\(\\)\"\n                matches = re.findall(pattern, text)\n                \n                if matches:\n                    verses = []\n                    for i, verse in enumerate(matches):\n                        verses.append({\n                            \"Surah\": (i // 10) + 1,\n                            \"Ayah\": (i % 10) + 1,\n                            \"Translation\": verse.strip()\n                        })\n                    \n                    self.data = pd.DataFrame(verses)\n                    logger.info(f\"Created dataset from paste.txt content with {len(verses)} verses\")\n            except Exception as e:\n                logger.warning(f\"Failed to extract from paste.txt: {e}\")\n        \n        # 5. Use hard-coded fallback data if all else fails\n        if self.data is None:\n            logger.warning(\"All data loading methods failed. Using fallback dataset.\")\n            self.data = pd.DataFrame([\n                {\"Surah\": 1, \"Ayah\": 1, \"Translation\": \"بسم اللہ الرحمن الرحیم\"},\n                {\"Surah\": 1, \"Ayah\": 2, \"Translation\": \"الحمد للہ رب العالمین\"},\n                {\"Surah\": 1, \"Ayah\": 3, \"Translation\": \"الرحمن الرحیم\"},\n                {\"Surah\": 1, \"Ayah\": 4, \"Translation\": \"مالک یوم الدین\"},\n                {\"Surah\": 1, \"Ayah\": 5, \"Translation\": \"ایاک نعبد و ایاک نستعین\"},\n                {\"Surah\": 1, \"Ayah\": 6, \"Translation\": \"اھدنا الصراط المستقیم\"},\n                {\"Surah\": 1, \"Ayah\": 7, \"Translation\": \"صراط الذین انعمت علیھم غیر المغضوب علیھم و لا الضالین\"},\n                {\"Surah\": 2, \"Ayah\": 1, \"Translation\": \"الم\"},\n                {\"Surah\": 2, \"Ayah\": 2, \"Translation\": \"ذٰلِکَ الْکِتٰبُ لَا رَیْبَ ۚ فِیْہِ ۚ ہُدًی لِّلْمُتَّقِیْنَ\"},\n                {\"Surah\": 112, \"Ayah\": 1, \"Translation\": \"قل هو الله احد\"},\n                {\"Surah\": 112, \"Ayah\": 2, \"Translation\": \"الله الصمد\"},\n                {\"Surah\": 112, \"Ayah\": 3, \"Translation\": \"لم يلد ولم يولد\"},\n                {\"Surah\": 112, \"Ayah\": 4, \"Translation\": \"ولم يكن له كفوا احد\"}\n            ])\n        \n        # Load surah names\n        self.load_surah_names()\n        \n        # Cache the processed data\n        try:\n            with open(cache_path, 'wb') as f:\n                pickle.dump(self.data, f)\n            logger.info(f\"Cached processed data to {cache_path}\")\n        except Exception as e:\n            logger.warning(f\"Failed to cache data: {e}\")\n        \n        # Add normalized text column for improved matching\n        if 'Translation' in self.data.columns:\n            self.data['NormalizedText'] = self.data['Translation'].apply(self.normalize_arabic_text)\n            \n            # Add combined reference string for convenience\n            self.data['Reference'] = self.data.apply(\n                lambda x: f\"Surah {x['Surah']}:{x['Ayah']}\" + \n                        (f\" ({self.surah_names.get(x['Surah'], '')})\" if x['Surah'] in self.surah_names else \"\"), \n                axis=1\n            )\n        else:\n            logger.error(\"Data loaded but 'Translation' column not found. Check data format.\")\n            return False\n        \n        return True\n    \n    def load_surah_names(self):\n        \"\"\"Load Surah names from various possible sources\"\"\"\n        # First try to load from cache\n        cache_path = self.cache_dir / \"surah_names.json\"\n        if cache_path.exists():\n            try:\n                with open(cache_path, 'r', encoding='utf-8') as f:\n                    self.surah_names = json.load(f)\n                return\n            except:\n                pass\n        \n        # Hardcoded names as fallback\n        self.surah_names = {\n            1: \"الفاتحة (Al-Fatiha)\",\n            2: \"البقرة (Al-Baqara)\",\n            3: \"آل عمران (Aal-Imran)\",\n            4: \"النساء (An-Nisa)\",\n            5: \"المائدة (Al-Ma'ida)\",\n            6: \"الأنعام (Al-An'am)\",\n            112: \"الإخلاص (Al-Ikhlas)\",\n            113: \"الفلق (Al-Falaq)\",\n            114: \"الناس (An-Nas)\"\n        }\n        \n        # Try to find a surah names file\n        possible_paths = [\n            '/kaggle/input/quran-metadata/surah_names.json',\n            '/kaggle/input/quran-urdu-translation/surah_names.json',\n            'data/surah_names.json'\n        ]\n        \n        for path in possible_paths:\n            try:\n                with open(path, 'r', encoding='utf-8') as f:\n                    self.surah_names = json.load(f)\n                logger.info(f\"Loaded surah names from {path}\")\n                break\n            except:\n                continue\n        \n        # Cache the names\n        try:\n            with open(cache_path, 'w', encoding='utf-8') as f:\n                json.dump(self.surah_names, f, ensure_ascii=False, indent=2)\n        except:\n            pass\n    \n    def initialize_search_methods(self):\n        \"\"\"Initialize multiple search methods for robust text retrieval\"\"\"\n        if self.data is None or len(self.data) == 0:\n            logger.error(\"No data available. Please load data first.\")\n            return False\n        \n        # 1. Initialize TF-IDF vectorizer\n        logger.info(\"Initializing TF-IDF vectorizer...\")\n        try:\n            self.vectorizer = TfidfVectorizer(\n                min_df=1, \n                max_df=0.9,\n                ngram_range=(1, 3),\n                sublinear_tf=True\n            )\n            self.tfidf_matrix = self.vectorizer.fit_transform(self.data['NormalizedText'])\n            logger.info(f\"TF-IDF matrix shape: {self.tfidf_matrix.shape}\")\n        except Exception as e:\n            logger.warning(f\"Failed to initialize TF-IDF: {e}\")\n        \n        # 2. Try to initialize sentence transformer (if available)\n        try:\n            from sentence_transformers import SentenceTransformer\n            \n            # Try loading cached embeddings first\n            embeddings_path = self.cache_dir / \"sentence_embeddings.npy\"\n            if embeddings_path.exists():\n                try:\n                    self.sentence_embeddings = np.load(embeddings_path)\n                    logger.info(f\"Loaded sentence embeddings from cache: {embeddings_path}\")\n                    self.sentence_transformer = True  # Just a flag that we have embeddings\n                except Exception as e:\n                    logger.warning(f\"Failed to load cached embeddings: {e}\")\n            \n            # If not loaded from cache, try to generate them\n            if self.sentence_embeddings is None:\n                try:\n                    # Try multilingual model first\n                    model_name = 'paraphrase-multilingual-MiniLM-L12-v2'\n                    self.sentence_transformer = SentenceTransformer(model_name)\n                    \n                    # Compute embeddings (may take time for large datasets)\n                    logger.info(f\"Computing sentence embeddings using {model_name}...\")\n                    self.sentence_embeddings = self.sentence_transformer.encode(\n                        self.data['Translation'].tolist(), \n                        show_progress_bar=True,\n                        batch_size=32\n                    )\n                    \n                    # Cache the embeddings\n                    try:\n                        np.save(embeddings_path, self.sentence_embeddings)\n                        logger.info(f\"Cached sentence embeddings to {embeddings_path}\")\n                    except Exception as e:\n                        logger.warning(f\"Failed to cache embeddings: {e}\")\n                        \n                except Exception as e:\n                    logger.warning(f\"Failed to initialize sentence transformer: {e}\")\n                    self.sentence_transformer = None\n        except ImportError:\n            logger.info(\"SentenceTransformer not available. Skipping semantic search capabilities.\")\n            self.sentence_transformer = None\n        \n        # 3. Initialize QA model if transformers is available\n        try:\n            from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n            \n            # Only initialize if data is large enough to be useful\n            if len(self.data) > 10:\n                logger.info(\"Initializing QA model...\")\n                try:\n                    model_name = \"bert-base-multilingual-cased\"\n                    self.qa_tokenizer = AutoTokenizer.from_pretrained(model_name)\n                    self.qa_model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n                    logger.info(\"QA model initialized successfully\")\n                except Exception as e:\n                    logger.warning(f\"Failed to initialize QA model: {e}\")\n        except ImportError:\n            logger.info(\"Transformers not available. Skipping QA capabilities.\")\n        \n        logger.info(\"Search methods initialization complete\")\n        return True\n    \n    def search(self, query, top_k=5, include_partial=True, include_similar=True, threshold=0.1):\n        \"\"\"\n        Search for verses matching the query using multiple techniques\n        \n        Args:\n            query: The search query text\n            top_k: Number of results to return\n            include_partial: Whether to include partial matches\n            include_similar: Whether to include semantically similar results\n            threshold: Similarity threshold for including results\n            \n        Returns:\n            Dictionary with primary match and other matches\n        \"\"\"\n        if self.data is None or len(self.data) == 0:\n            return {\"error\": \"No data available. Please load data first.\"}\n        \n        # Handle empty query\n        if not query or not isinstance(query, str):\n            return {\"error\": \"Empty or invalid query\", \"primary_match\": None, \"other_matches\": [], \"total_matches\": 0}\n        \n        # Normalize the query\n        normalized_query = self.normalize_arabic_text(query)\n        \n        # Dictionary to store all matches with their scores and methods\n        all_matches = defaultdict(lambda: {\"score\": 0, \"methods\": []})\n        \n        # 1. Look for exact matches first (highest priority)\n        exact_indices = []\n        for idx, row in self.data.iterrows():\n            if query in row['Translation'] or normalized_query in row['NormalizedText']:\n                match_key = f\"{row['Surah']}:{row['Ayah']}\"\n                all_matches[match_key][\"verse\"] = row['Translation']\n                all_matches[match_key][\"reference\"] = row['Reference']\n                all_matches[match_key][\"score\"] += 10  # High score for exact match\n                all_matches[match_key][\"methods\"].append(\"exact\")\n                exact_indices.append(idx)\n        \n        # 2. Use TF-IDF for partial keyword matching\n        if self.vectorizer is not None and (include_partial or len(all_matches) < top_k):\n            try:\n                query_vec = self.vectorizer.transform([normalized_query])\n                similarity_scores = cosine_similarity(query_vec, self.tfidf_matrix).flatten()\n                \n                # Get indices of top matches\n                top_indices = similarity_scores.argsort()[-top_k*2:][::-1]\n                \n                for idx in top_indices:\n                    if similarity_scores[idx] > threshold:\n                        row = self.data.iloc[idx]\n                        match_key = f\"{row['Surah']}:{row['Ayah']}\"\n                        \n                        # Only add if not already an exact match or update score if better\n                        if match_key not in all_matches or all_matches[match_key][\"score\"] < similarity_scores[idx] * 5:\n                            all_matches[match_key][\"verse\"] = row['Translation']\n                            all_matches[match_key][\"reference\"] = row['Reference']\n                            all_matches[match_key][\"score\"] = max(all_matches[match_key][\"score\"], similarity_scores[idx] * 5)\n                            all_matches[match_key][\"methods\"].append(\"tfidf\")\n            except Exception as e:\n                logger.warning(f\"TF-IDF search failed: {e}\")\n        \n        # 3. Use semantic search with sentence embeddings\n        if self.sentence_transformer is not None and self.sentence_embeddings is not None and include_similar:\n            try:\n                # If it's just a flag, we only have cached embeddings\n                if isinstance(self.sentence_transformer, bool):\n                    # Use a simpler approach with dot product\n                    from sentence_transformers import SentenceTransformer\n                    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n                    query_embedding = model.encode([query])[0]\n                    \n                    # Calculate similarities\n                    similarities = np.dot(self.sentence_embeddings, query_embedding)\n                    top_indices = similarities.argsort()[-top_k*2:][::-1]\n                    \n                    for idx in top_indices:\n                        if similarities[idx] > threshold:\n                            row = self.data.iloc[idx]\n                            match_key = f\"{row['Surah']}:{row['Ayah']}\"\n                            \n                            all_matches[match_key][\"verse\"] = row['Translation']\n                            all_matches[match_key][\"reference\"] = row['Reference']\n                            all_matches[match_key][\"score\"] = max(all_matches[match_key][\"score\"], similarities[idx] * 3)\n                            all_matches[match_key][\"methods\"].append(\"semantic\")\n                else:\n                    # Use the model directly\n                    query_embedding = self.sentence_transformer.encode([query])[0]\n                    \n                    # Calculate similarities\n                    similarities = np.dot(self.sentence_embeddings, query_embedding)\n                    top_indices = similarities.argsort()[-top_k*2:][::-1]\n                    \n                    for idx in top_indices:\n                        if similarities[idx] > threshold:\n                            row = self.data.iloc[idx]\n                            match_key = f\"{row['Surah']}:{row['Ayah']}\"\n                            \n                            all_matches[match_key][\"verse\"] = row['Translation']\n                            all_matches[match_key][\"reference\"] = row['Reference']\n                            all_matches[match_key][\"score\"] = max(all_matches[match_key][\"score\"], similarities[idx] * 3)\n                            all_matches[match_key][\"methods\"].append(\"semantic\")\n            except Exception as e:\n                logger.warning(f\"Semantic search failed: {e}\")\n        \n        # 4. Use fuzzy matching for query with typos\n        if include_partial and len(all_matches) < top_k:\n            for idx, row in self.data.iterrows():\n                # Skip already matched verses\n                match_key = f\"{row['Surah']}:{row['Ayah']}\"\n                if match_key in all_matches:\n                    continue\n                \n                # Calculate fuzzy match ratio\n                ratio = difflib.SequenceMatcher(None, normalized_query, row['NormalizedText']).ratio()\n                \n                if ratio > max(0.6, threshold * 2):  # Higher threshold for fuzzy matching\n                    all_matches[match_key][\"verse\"] = row['Translation']\n                    all_matches[match_key][\"reference\"] = row['Reference']\n                    all_matches[match_key][\"score\"] = max(all_matches[match_key][\"score\"], ratio * 2)\n                    all_matches[match_key][\"methods\"].append(\"fuzzy\")\n        \n        # Sort matches by score\n        sorted_matches = sorted(all_matches.items(), key=lambda x: x[1][\"score\"], reverse=True)\n        \n        # Prepare results\n        results = {\n            \"primary_match\": None,\n            \"other_matches\": [],\n            \"total_matches\": len(sorted_matches)\n        }\n        \n        # Set primary match (the one with highest score)\n        if sorted_matches:\n            primary = sorted_matches[0][1]\n            results[\"primary_match\"] = {\n                \"verse\": primary[\"verse\"],\n                \"reference\": primary[\"reference\"],\n                \"score\": primary[\"score\"],\n                \"methods\": primary[\"methods\"]\n            }\n            \n            # Add other matches\n            other_matches = []\n            for _, match in sorted_matches[1:top_k]:\n                other_matches.append({\n                    \"verse\": match[\"verse\"],\n                    \"reference\": match[\"reference\"],\n                    \"score\": match[\"score\"],\n                    \"methods\": match[\"methods\"]\n                })\n            \n            results[\"other_matches\"] = other_matches\n        \n        return results\n    \n    def answer_question(self, question, context=None, max_length=512):\n        \"\"\"\n        Answer a question using the QA model.\n        \n        Args:\n            question: The question to answer\n            context: Optional context to use, otherwise will search for relevant verses\n            \n        Returns:\n            Dictionary with answer and reference\n        \"\"\"\n        if self.qa_model is None or self.qa_tokenizer is None:\n            return {\"error\": \"QA model not available\"}\n        \n        try:\n            from transformers import pipeline\n            qa_pipeline = pipeline(\"question-answering\", model=self.qa_model, tokenizer=self.qa_tokenizer)\n            \n            # Get context if not provided\n            if context is None:\n                search_results = self.search(question, top_k=3)\n                \n                if search_results[\"primary_match\"]:\n                    context = search_results[\"primary_match\"][\"verse\"]\n                    \n                    # Add some additional context if available\n                    for match in search_results[\"other_matches\"][:2]:\n                        context += \" \" + match[\"verse\"]\n                else:\n                    return {\"error\": \"No relevant context found for the question\"}\n            \n            # Use the QA pipeline to get an answer\n            result = qa_pipeline(question=question, context=context, max_length=max_length)\n            \n            return {\n                \"answer\": result[\"answer\"],\n                \"score\": result[\"score\"],\n                \"context\": context\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error in answer_question: {e}\")\n            return {\"error\": f\"Failed to answer question: {str(e)}\"}\n\n    def formatted_search_results(self, query, top_k=5):\n        \"\"\"\n        Return search results in a nicely formatted string.\n        \n        Args:\n            query: The search query\n            top_k: Number of results to return\n            \n        Returns:\n            Formatted string with search results\n        \"\"\"\n        results = self.search(query, top_k=top_k)\n        \n        if \"error\" in results:\n            return f\"Error: {results['error']}\"\n        \n        output = [f\"Search results for: '{query}'\"]\n        output.append(\"=\" * 50)\n        \n        if results[\"primary_match\"]:\n            primary = results[\"primary_match\"]\n            output.append(\"Primary Match:\")\n            output.append(f\"📖 {primary['reference']}\")\n            output.append(f\"📝 {primary['verse']}\")\n            output.append(f\"✓ Match score: {primary['score']:.2f} using {', '.join(primary['methods'])}\")\n            output.append(\"-\" * 50)\n        else:\n            output.append(\"No primary match found.\")\n            output.append(\"-\" * 50)\n        \n        if results[\"other_matches\"]:\n            output.append(\"Other Relevant Matches:\")\n            for i, match in enumerate(results[\"other_matches\"], 1):\n                output.append(f\"{i}. 📖 {match['reference']}\")\n                output.append(f\"   📝 {match['verse']}\")\n                output.append(f\"   ✓ Match score: {match['score']:.2f} using {', '.join(match['methods'])}\")\n                output.append(\"   \" + \"-\" * 40)\n        else:\n            output.append(\"No other matches found.\")\n        \n        output.append(f\"\\nTotal matches: {results['total_matches']}\")\n        \n        return \"\\n\".join(output)\n\ndef initialize_search_engine():\n    \"\"\"Helper function to initialize the search engine\"\"\"\n    engine = EnhancedQuranSearchEngine()\n    success = engine.load_data_from_multiple_sources()\n    \n    if success:\n        engine.initialize_search_methods()\n        logger.info(f\"Engine initialized with {len(engine.data)} verses\")\n        return engine\n    else:\n        logger.error(\"Failed to initialize search engine\")\n        return None\n\ndef main():\n    \"\"\"Main function to demonstrate search capabilities\"\"\"\n    logger.info(\"Starting Quran Search Engine\")\n    \n    # Initialize engine\n    engine = initialize_search_engine()\n    \n    if not engine:\n        logger.error(\"Engine initialization failed. Exiting.\")\n        return\n    \n    # Example search\n    test_queries = [\n        \"رحمن\",\n        \"نماز\",\n        \"جنت\",\n        \"توبه\",\n        \"صبر\"\n    ]\n    \n    for query in test_queries:\n        logger.info(f\"\\nTesting search for: '{query}'\")\n        results = engine.formatted_search_results(query)\n        print(results)\n    \n    # Interactive mode\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Interactive Quran Search Engine\")\n    print(\"=\" * 60)\n    print(\"Enter your search query (or 'exit' to quit):\")\n    \n    while True:\n        query = input(\"\\nSearch: \")\n        if query.lower() in ['exit', 'quit', 'q']:\n            break\n        \n        if not query.strip():\n            continue\n            \n        results = engine.formatted_search_results(query)\n        print(results)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:14:42.279409Z","iopub.execute_input":"2025-04-01T18:14:42.279763Z","iopub.status.idle":"2025-04-01T18:17:21.228607Z","shell.execute_reply.started":"2025-04-01T18:14:42.279739Z","shell.execute_reply":"2025-04-01T18:17:21.227834Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a02c9356917b4074b13cbd34e8fa9301"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd2ec0d497ef401f9baf9cfd28023aff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a7e79e3d0ba461d8baa87b265b5a04e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a8ea04896645c69cefe1fec7065f24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d27de39dd3614196a203d0820dfe01a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee1217f89d7f452bacca73b52633b2b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4eca20b52b44c98917d660ed6dd9316"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ba43b5557b94353955f059a5021a677"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe4bee062774498b9e475a9b9b3cef0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"861b97984c0044ae8d5ba65a8b3069fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/195 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c592635d43754f6c9372c017afec325f"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ea729eff30e4525bd2b1c12617d37b6"}},"metadata":{}},{"name":"stdout","text":"Search results for: 'رحمن'\n==================================================\nPrimary Match:\n📖 Surah 32:1\n📝 الٓمٓ\n✓ Match score: 28.49 using semantic\n--------------------------------------------------\nOther Relevant Matches:\n1. 📖 Surah 31:1\n   📝 الٓمٓ\n   ✓ Match score: 28.49 using semantic\n   ----------------------------------------\n2. 📖 Surah 30:1\n   📝 الٓمٓ\n   ✓ Match score: 28.49 using semantic\n   ----------------------------------------\n3. 📖 Surah 42:1\n   📝 حٰمٓ\n   ✓ Match score: 28.00 using semantic\n   ----------------------------------------\n4. 📖 Surah 40:1\n   📝 حٰم\n   ✓ Match score: 27.60 using semantic\n   ----------------------------------------\n\nTotal matches: 22\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb75935b01f14eda98c704e987569aa3"}},"metadata":{}},{"name":"stdout","text":"Search results for: 'نماز'\n==================================================\nPrimary Match:\n📖 Surah 70:22\n📝 مگر نماز گزار\n✓ Match score: 57.42 using exact, semantic\n--------------------------------------------------\nOther Relevant Matches:\n1. 📖 Surah 96:10\n   📝 (یعنی) ایک بندے کو جب وہ نماز پڑھنے لگتا ہے\n   ✓ Match score: 56.05 using exact, semantic\n   ----------------------------------------\n2. 📖 Surah 108:2\n   📝 تو اپنے پروردگار کے لیے نماز پڑھا کرو اور قربانی دیا کرو\n   ✓ Match score: 55.77 using exact, semantic\n   ----------------------------------------\n3. 📖 Surah 23:2\n   📝 جو نماز میں عجزو نیاز کرتے ہیں\n   ✓ Match score: 53.31 using exact, semantic\n   ----------------------------------------\n4. 📖 Surah 70:34\n   📝 اور جو اپنی نماز کی خبر رکھتے ہیں\n   ✓ Match score: 51.55 using exact, semantic\n   ----------------------------------------\n\nTotal matches: 101\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e981fb1c5ab42d693b861076c82a81f"}},"metadata":{}},{"name":"stdout","text":"Search results for: 'جنت'\n==================================================\nPrimary Match:\n📖 Surah 74:3\n📝 اور اپنے پروردگار کی بڑائی کرو\n✓ Match score: 38.05 using semantic\n--------------------------------------------------\nOther Relevant Matches:\n1. 📖 Surah 53:15\n   📝 اسی کے پاس رہنے کی جنت ہے\n   ✓ Match score: 36.42 using exact, semantic\n   ----------------------------------------\n2. 📖 Surah 70:22\n   📝 مگر نماز گزار\n   ✓ Match score: 35.99 using semantic\n   ----------------------------------------\n3. 📖 Surah 43:72\n   📝 اور یہ جنت جس کے تم مالک کر دیئے گئے ہو تمہارے اعمال کا صلہ ہے\n   ✓ Match score: 35.45 using exact, semantic\n   ----------------------------------------\n4. 📖 Surah 36:58\n   📝 پروردگار مہربان کی طرف سے سلام (کہا جائے گا)\n   ✓ Match score: 35.27 using semantic\n   ----------------------------------------\n\nTotal matches: 27\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3d64340eb394bcb9ccd6de11a053978"}},"metadata":{}},{"name":"stdout","text":"Search results for: 'توبه'\n==================================================\nPrimary Match:\n📖 Surah 2:52 (البقرة (Al-Baqara))\n📝 پھر اس کے بعد ہم نے تم کو معاف کر دیا، تاکہ تم شکر کرو\n✓ Match score: 36.72 using semantic\n--------------------------------------------------\nOther Relevant Matches:\n1. 📖 Surah 42:43\n   📝 اور جو صبر کرے اور قصور معاف کردے تو یہ ہمت کے کام ہیں\n   ✓ Match score: 34.46 using semantic\n   ----------------------------------------\n2. 📖 Surah 23:106\n   📝 اے ہمارے پروردگار! ہم پر ہماری کم بختی غالب ہوگئی اور ہم رستے سے بھٹک گئے\n   ✓ Match score: 31.36 using semantic\n   ----------------------------------------\n3. 📖 Surah 2:160 (البقرة (Al-Baqara))\n   📝 ہاں جو توبہ کرتے ہیں اور اپنی حالت درست کرلیتے اور (احکام الہیٰ کو) صاف صاف بیان کردیتے ہیں تو میں ان کے قصور معاف کردیتا ہوں اور میں بڑا معاف کرنے والا (اور) رحم والا ہوں\n   ✓ Match score: 31.21 using semantic\n   ----------------------------------------\n4. 📖 Surah 75:35\n   📝 پھر افسوس ہے تجھ پر پھر افسوس ہے\n   ✓ Match score: 30.97 using semantic\n   ----------------------------------------\n\nTotal matches: 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"976a8fcc45ac492bbfb666882666a37f"}},"metadata":{}},{"name":"stdout","text":"Search results for: 'صبر'\n==================================================\nPrimary Match:\n📖 Surah 44:59\n📝 پس تم بھی انتظار کرو یہ بھی انتظار کر رہے ہیں\n✓ Match score: 39.91 using semantic\n--------------------------------------------------\nOther Relevant Matches:\n1. 📖 Surah 74:7\n   📝 اور اپنے پروردگار کے لئے صبر کرو\n   ✓ Match score: 38.87 using exact, semantic\n   ----------------------------------------\n2. 📖 Surah 11:122\n   📝 اور (نتیجہٴ اعمال کا) تم بھی انتظار کرو، ہم بھی انتظار کرتے ہیں\n   ✓ Match score: 36.30 using semantic\n   ----------------------------------------\n3. 📖 Surah 52:31\n   📝 کہہ دو کہ انتظار کئے جاؤ میں بھی تمہارے ساتھ انتظار کرتا ہوں\n   ✓ Match score: 30.51 using semantic\n   ----------------------------------------\n4. 📖 Surah 73:2\n   📝 رات کو قیام کیا کرو مگر تھوڑی سی رات\n   ✓ Match score: 29.43 using semantic\n   ----------------------------------------\n\nTotal matches: 77\n\n============================================================\nInteractive Quran Search Engine\n============================================================\nEnter your search query (or 'exit' to quit):\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nSearch:  exit\n"}],"execution_count":3},{"cell_type":"code","source":"# kaggle_create_model.py\n\"\"\"\nThis script is designed to run on Kaggle to:\n1. Create the Quran search engine model\n2. Save it in a format that can be downloaded\n\"\"\"\nimport pickle\nimport os\nimport sys\nfrom pathlib import Path\nimport logging\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('KaggleModelCreation')\n\n\n\ndef create_and_save_model():\n    \"\"\"Create and save the search engine model on Kaggle\"\"\"\n    # Create output directory for the model\n    output_dir = Path('/kaggle/working/model_output')\n    output_dir.mkdir(exist_ok=True, parents=True)\n    \n    # Initialize the search engine\n    logger.info(\"Initializing search engine...\")\n    engine = EnhancedQuranSearchEngine(cache_dir=str(output_dir))\n    \n    # Load data and initialize search methods\n    success = engine.load_data_from_multiple_sources()\n    if not success:\n        logger.error(\"Failed to load data for search engine\")\n        return False\n    \n    engine.initialize_search_methods()\n    \n    # Save the model to a file that can be downloaded\n    model_path = output_dir / \"quran_search_engine.pkl\"\n    try:\n        with open(model_path, 'wb') as f:\n            pickle.dump(engine, f)\n        logger.info(f\"Model saved to {model_path}\")\n        \n        # Get model stats for reporting\n        data_count = len(engine.data) if hasattr(engine, 'data') else 0\n        has_tfidf = engine.vectorizer is not None if hasattr(engine, 'vectorizer') else False\n        has_st = engine.sentence_transformer is not None if hasattr(engine, 'sentence_transformer') else False\n        \n        print(\"\\n\" + \"=\"*50)\n        print(\"MODEL CREATION SUCCESSFUL\")\n        print(\"=\"*50)\n        print(f\"Model saved to: {model_path}\")\n        print(f\"Verses loaded: {data_count}\")\n        print(f\"TF-IDF vectorizer: {'Enabled' if has_tfidf else 'Disabled'}\")\n        print(f\"Semantic search: {'Enabled' if has_st else 'Disabled'}\")\n        print(\"\\nIMPORTANT: Download this file from the Kaggle output\")\n        print(\"=\"*50)\n        \n        return True\n    except Exception as e:\n        logger.error(f\"Failed to save model: {e}\")\n        return False\n\n# Run the model creation\nif __name__ == \"__main__\":\n    create_and_save_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T18:22:00.556725Z","iopub.execute_input":"2025-04-01T18:22:00.557083Z","iopub.status.idle":"2025-04-01T18:22:12.387211Z","shell.execute_reply.started":"2025-04-01T18:22:00.557053Z","shell.execute_reply":"2025-04-01T18:22:12.386247Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/195 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f9e193ccbad47b7ab345809612828b5"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nMODEL CREATION SUCCESSFUL\n==================================================\nModel saved to: /kaggle/working/model_output/quran_search_engine.pkl\nVerses loaded: 6236\nTF-IDF vectorizer: Enabled\nSemantic search: Enabled\n\nIMPORTANT: Download this file from the Kaggle output\n==================================================\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}